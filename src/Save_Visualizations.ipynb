{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1744e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../detr\")\n",
    "from engine import evaluate, train_one_epoch\n",
    "from models import build_model\n",
    "import util.misc as utils\n",
    "import datasets.transforms as R\n",
    "from models import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82874d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from table_datasets import PDFTablesDataset, TightAnnotationCrop, RandomPercentageCrop, RandomErasingWithTarget, ToPILImageWithTarget, RandomMaxResize, RandomCrop\n",
    "from eval import eval_coco, eval_tsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeb91868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import get_class_map, get_transform, get_data, get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6695d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09fcb3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e965c4fb",
   "metadata": {},
   "source": [
    "## Detection Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52769558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_load_path = \"../detection_train_output/20220520164328/model_20.pth\"\n",
    "model_load_path = \"../pubtables1m_detection_detr_r18.pth\"\n",
    "data_type = \"detection\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad5b48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 5e-05, 'lr_backbone': 1e-05, 'batch_size': 2, 'weight_decay': 0.0001, 'epochs': 20, 'lr_drop': 1, 'lr_gamma': 0.9, 'clip_max_norm': 0.1, 'backbone': 'resnet18', 'num_classes': 2, 'dilation': False, 'position_embedding': 'sine', 'emphasized_weights': {}, 'enc_layers': 6, 'dec_layers': 6, 'dim_feedforward': 2048, 'hidden_dim': 256, 'dropout': 0.1, 'nheads': 8, 'num_queries': 15, 'pre_norm': True, 'masks': False, 'aux_loss': False, 'mask_loss_coef': 1, 'dice_loss_coef': 1, 'ce_loss_coef': 1, 'bbox_loss_coef': 5, 'giou_loss_coef': 2, 'eos_coef': 0.4, 'set_cost_class': 1, 'set_cost_bbox': 5, 'set_cost_giou': 2, 'device': 'cuda', 'seed': 42, 'start_epoch': 0, 'num_workers': 1, '__module__': '__main__', '__dict__': <attribute '__dict__' of 'Args' objects>, '__weakref__': <attribute '__weakref__' of 'Args' objects>, '__doc__': None, 'model_load_path': '../pubtables1m_detection_detr_r18.pth', 'data_type': 'detection', 'mode': 'eval', 'data_root_dir': '/home/shiki/hdd/WikiTableExtraction/detection'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loading model\n",
      "loading model from checkpoint\n",
      "loading data\n",
      "found xml from /home/shiki/hdd/WikiTableExtraction/detection/test/../test_filelist.txt 3809\n",
      "list dir 37958 /home/shiki/hdd/WikiTableExtraction/detection/test/../images .png\n",
      "found images from /home/shiki/hdd/WikiTableExtraction/detection/test/../images/filelist.txt 37958\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SetCriterion(\n",
       "  (matcher): HungarianMatcher()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_args = json.load(open(f\"{data_type}_config.json\", 'rb'))\n",
    "args = type('Args', (object,), config_args)\n",
    "args.model_load_path = model_load_path\n",
    "args.data_type = data_type\n",
    "args.mode = \"eval\"\n",
    "args.data_root_dir = f\"/home/shiki/hdd/WikiTableExtraction/{data_type}\"\n",
    "print(args.__dict__)\n",
    "print('-' * 100)\n",
    "\n",
    "# fix the seed for reproducibility\n",
    "seed = args.seed + utils.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "print(\"loading model\")\n",
    "device = torch.device(args.device)\n",
    "model, criterion, postprocessors = get_model(args, device)\n",
    "\n",
    "data_loader_test, dataset_test = get_data(args)\n",
    "model.eval()\n",
    "criterion.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85467bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = \"../detection_train_output/pretrained_vis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4576bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def save_detection(model, postprocessors, base_ds, device, thresh=0.5):\n",
    "    idx = np.random.choice(range(len(base_ds)))\n",
    "    for idx in tqdm(range(len(base_ds))):\n",
    "        page_id = base_ds.page_ids[idx]\n",
    "        img_path = os.path.join(base_ds.root, \"..\", \"images\", page_id + base_ds.image_extension)\n",
    "        annot_path = os.path.join(base_ds.root, page_id + \".xml\")\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        samples = [base_ds[idx][0].to(device)]\n",
    "        targets = [{k: v.to(device) for k, v in base_ds[idx][1].items()}]\n",
    "        outputs = model(samples)\n",
    "\n",
    "        orig_target_sizes = torch.stack([t[\"orig_size\"] for t in targets], dim=0)\n",
    "        results = postprocessors['bbox'](outputs, orig_target_sizes)\n",
    "\n",
    "        for score, bbox in zip(results[0]['scores'], results[0]['boxes']):\n",
    "            if score.cpu().item() < thresh:\n",
    "                continue\n",
    "            bbox = bbox.cpu().numpy().flatten()\n",
    "            draw.rectangle(bbox, outline='red', width=2)\n",
    "#         for bbox in targets[0]['boxes']:\n",
    "#             bbox = bbox.cpu().numpy().flatten()\n",
    "#             print(bbox)\n",
    "#             draw.rectangle(bbox, outline='green', width=2)\n",
    "#         print(page_id)\n",
    "        img.save(f\"{OUT_PATH}/{page_id}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fadf53d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3809/3809 [28:31<00:00,  2.23it/s]  \n"
     ]
    }
   ],
   "source": [
    "save_detection(model, postprocessors, dataset_test, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e99f29",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59d53434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 5e-05, 'lr_backbone': 1e-05, 'batch_size': 2, 'weight_decay': 0.0001, 'epochs': 20, 'lr_drop': 1, 'lr_gamma': 0.9, 'clip_max_norm': 0.1, 'backbone': 'resnet18', 'num_classes': 6, 'dilation': False, 'position_embedding': 'sine', 'emphasized_weights': {}, 'enc_layers': 6, 'dec_layers': 6, 'dim_feedforward': 2048, 'hidden_dim': 256, 'dropout': 0.1, 'nheads': 8, 'num_queries': 125, 'pre_norm': True, 'masks': False, 'aux_loss': False, 'mask_loss_coef': 1, 'dice_loss_coef': 1, 'ce_loss_coef': 1, 'bbox_loss_coef': 5, 'giou_loss_coef': 2, 'eos_coef': 0.4, 'set_cost_class': 1, 'set_cost_bbox': 5, 'set_cost_giou': 2, 'device': 'cuda', 'seed': 42, 'start_epoch': 0, 'num_workers': 1, '__module__': '__main__', '__dict__': <attribute '__dict__' of 'Args' objects>, '__weakref__': <attribute '__weakref__' of 'Args' objects>, '__doc__': None, 'model_load_path': '../structure_train_output/20220521084016/model_20.pth', 'data_type': 'structure', 'mode': 'eval', 'data_root_dir': '/home/shiki/hdd/WikiTableExtraction/structure'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "loading model\n",
      "loading model from checkpoint\n",
      "loading data\n",
      "found xml from /home/shiki/hdd/WikiTableExtraction/structure/test/../test_filelist.txt 10272\n",
      "list dir 102746 /home/shiki/hdd/WikiTableExtraction/structure/test/../images .png\n",
      "found images from /home/shiki/hdd/WikiTableExtraction/structure/test/../images/filelist.txt 102746\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SetCriterion(\n",
       "  (matcher): HungarianMatcher()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load_path = \"../structure_train_output/20220521084016/model_20.pth\"\n",
    "# model_load_path = \"../pubtables1m_structure_detr_r18.pth\"\n",
    "data_type = \"structure\"\n",
    "config_args = json.load(open(f\"{data_type}_config.json\", 'rb'))\n",
    "args = type('Args', (object,), config_args)\n",
    "args.model_load_path = model_load_path\n",
    "args.data_type = data_type\n",
    "args.mode = \"eval\"\n",
    "args.data_root_dir = f\"/home/shiki/hdd/WikiTableExtraction/{data_type}\"\n",
    "print(args.__dict__)\n",
    "print('-' * 100)\n",
    "\n",
    "# fix the seed for reproducibility\n",
    "seed = args.seed + utils.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "print(\"loading model\")\n",
    "device = torch.device(args.device)\n",
    "model, criterion, postprocessors = get_model(args, device)\n",
    "\n",
    "data_loader_test, dataset_test = get_data(args)\n",
    "model.eval()\n",
    "criterion.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5985b072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../structure_train_output/pretrained_vis’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# ! mkdir ../structure_train_output/pretrained_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c177682",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_color = {\n",
    "    0: 'red', \n",
    "    1: 'blue', \n",
    "    2: 'green', \n",
    "    3: 'purple', \n",
    "    4: 'gray',\n",
    "    5: 'orange'\n",
    "}\n",
    "\n",
    "OUT_PATH = \"/home/shiki/hdd/TableRecOut/detr/trained/structure\"\n",
    "\n",
    "@torch.no_grad()\n",
    "def random_show_structure(model, postprocessors, base_ds, device, thresh=0.9):\n",
    "    # idx = np.random.choice(range(len(base_ds)))\n",
    "    for idx in tqdm(range(len(base_ds))):\n",
    "        page_id = base_ds.page_ids[idx]\n",
    "        img_path = os.path.join(base_ds.root, \"..\", \"images\", page_id + base_ds.image_extension)\n",
    "        annot_path = os.path.join(base_ds.root, page_id + \".xml\")\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        samples = [base_ds[idx][0].to(device)]\n",
    "        targets = [{k: v.to(device) for k, v in base_ds[idx][1].items()}]\n",
    "        outputs = model(samples)\n",
    "\n",
    "        orig_target_sizes = torch.stack([t[\"orig_size\"] for t in targets], dim=0)\n",
    "        results = postprocessors['bbox'](outputs, orig_target_sizes)\n",
    "        for i in range(len(results[0]['boxes'])):\n",
    "            if results[0]['scores'][i] < thresh:\n",
    "                continue\n",
    "\n",
    "            bbox = results[0]['boxes'][i].cpu().numpy().flatten()\n",
    "            color = class_color[results[0]['labels'][i].cpu().item()]\n",
    "            draw.rectangle(bbox, outline=color, width=2)\n",
    "        img.save(f\"{OUT_PATH}/{page_id}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dafc381",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10272/10272 [24:38<00:00,  6.95it/s] \n"
     ]
    }
   ],
   "source": [
    "random_show_structure(model, postprocessors, dataset_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba5247b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
